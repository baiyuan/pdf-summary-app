import streamlit as st
import fitz  # PyMuPDF
import requests
import tempfile
import os
import langdetect

# è‡ªè¨‚ CSSï¼šé»‘åº•ç™½å­— + ChatGPT é¢¨æ ¼
st.markdown("""
    <style>
    body {
        background-color: #0d1117;
        color: #c9d1d9;
    }
    .stApp {
        background-color: #0d1117;
    }
    h1, h2, h3, h4, h5, h6 {
        color: #58a6ff;
    }
    .stTextArea, .stTextInput, .stSlider, .stButton button {
        background-color: #161b22;
        color: #c9d1d9;
        border: 1px solid #30363d;
    }
    .stButton button:hover {
        background-color: #238636;
        color: #ffffff;
    }
    .stMarkdown {
        color: #c9d1d9;
    }
    </style>
""", unsafe_allow_html=True)

# è¨­å®š Ollama API åƒæ•¸
OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "llama3"

# é é¢æ¨™é¡Œ
st.title("ğŸ“„ PDF æ™ºèƒ½æ‘˜è¦ & äº’å‹•å¼å•ç­” (ChatGPT é¢¨æ ¼)")

# ä¸Šå‚³ PDF
uploaded_file = st.file_uploader("ğŸ“¤ è«‹é¸æ“‡ä¸€å€‹ PDF æª”æ¡ˆ", type=["pdf"])

# ä½¿ç”¨è€…è¨­å®š
summary_count = st.slider("âœ¨ è¨­å®šæ‘˜è¦é‡é»æ•¸é‡", 3, 10, 5)

if uploaded_file is not None:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(uploaded_file.read())
        tmp_pdf_path = tmp_file.name

    # è®€å– PDF æ–‡å­— & é æ•¸
    doc = fitz.open(tmp_pdf_path)
    total_pages = doc.page_count
    st.info(f"ğŸ“– PDF é æ•¸ï¼š{total_pages} é ")

    all_page_texts = []
    for page in doc:
        text = page.get_text()
        all_page_texts.append(text)

    os.unlink(tmp_pdf_path)

    # è‡ªå‹•åµæ¸¬èªè¨€
    sample_text = "".join(all_page_texts[:3])
    try:
        lang = langdetect.detect(sample_text)
    except:
        lang = "unknown"

    lang_display = "ä¸­æ–‡" if lang.startswith("zh") else "è‹±æ–‡" if lang == "en" else "å…¶ä»–èªè¨€"
    st.info(f"ğŸŒ åµæ¸¬èªè¨€ï¼š{lang_display}")

    # å¤šé åˆ†æ®µæ‘˜è¦
    if st.button("ğŸ“„ åŸ·è¡Œå¤šé åˆ†æ®µæ‘˜è¦"):
        st.subheader("ğŸ“Œ åˆ†é æ‘˜è¦")
        for i, page_text in enumerate(all_page_texts):
            if page_text.strip() == "":
                continue
            with st.spinner(f"ç¬¬ {i+1} é æ‘˜è¦ä¸­..."):
                response = requests.post(
                    OLLAMA_URL,
                    json={
                        "model": MODEL_NAME,
                        "prompt": f"è«‹ç”¨ {summary_count} å€‹é‡é»æ‘˜è¦ä»¥ä¸‹ PDF ç¬¬ {i+1} é å…§å®¹ï¼š\n\n{page_text}"
                    }
                )
                result = response.json()
                st.markdown(f"**ç¬¬ {i+1} é æ‘˜è¦ï¼š**")
                st.write(result['response'])

    # äº’å‹•å¼æ‘˜è¦å•ç­”
    st.subheader("ğŸ’¬ äº’å‹•å¼æ‘˜è¦å•ç­”")
    chat_question = st.text_input("ğŸ“ è«‹è¼¸å…¥ä½ æƒ³å• PDF çš„å•é¡Œ")

    if st.button("ğŸ§  è©¢å• Ollama"):
        full_text = "\n".join(all_page_texts)
        with st.spinner("Ollama å›ç­”ä¸­..."):
            response = requests.post(
                OLLAMA_URL,
                json={
                    "model": MODEL_NAME,
                    "prompt": f"é€™æ˜¯ PDF æ–‡ä»¶å…¨æ–‡ï¼š\n\n{full_text}\n\næ ¹æ“šé€™ä»½å…§å®¹ï¼Œå›ç­”ä»¥ä¸‹å•é¡Œï¼š{chat_question}"
                }
            )
            result = response.json()
            st.markdown("**ğŸ“Œ å›ç­”çµæœï¼š**")
            st.write(result['response'])
